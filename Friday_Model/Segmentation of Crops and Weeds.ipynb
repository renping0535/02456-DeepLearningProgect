{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook file is the implementation of \"SegNet\" from the course \"02456 Deep Learning\" at DTU.\n",
    "The project is cooperated with Cellari under the guidance of Prof. Ole (DTU Compute) and Peter (Cellari).\n",
    "The main purpose is to segment the crops and weeds from a drone image.\n",
    "\n",
    "**Notice:**\n",
    "1. change the dataset path to your own!\n",
    "2. change the trained model saving path to your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:10:55.333163Z",
     "start_time": "2019-12-18T21:10:55.327832Z"
    }
   },
   "outputs": [],
   "source": [
    "# the path of your train data\n",
    "path_train_raw = '/home/renping/02456 DeepLearning Project/train/cropped/raw'\n",
    "path_train_anno = '/home/renping/02456 DeepLearning Project/train/cropped/anno'\n",
    "\n",
    "# the path of your test data\n",
    "path_test_raw = '/home/renping/02456 DeepLearning Project/test/cropped/raw'\n",
    "path_test_anno = '/home/renping/02456 DeepLearning Project/test/cropped/anno'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generator for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter in train batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:10:55.338342Z",
     "start_time": "2019-12-18T21:10:55.334182Z"
    }
   },
   "outputs": [],
   "source": [
    "batches = 10\n",
    "crop_size = 256\n",
    "path_train = path_train_raw\n",
    "path_anno = path_train_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:10:57.624603Z",
     "start_time": "2019-12-18T21:10:55.339474Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "from time import time\n",
    "\n",
    "# Functions to convert rgb segmaps to 2d\n",
    "\n",
    "# Convert rgb array to grayscale\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "# Mapping for grayscale original segmap\n",
    "mapping = {\n",
    "    0: 0,\n",
    "    76: 1,\n",
    "    149: 2,\n",
    "    225: 3\n",
    "}\n",
    "\n",
    "# Mapping for grayscale imgaug segmap\n",
    "mapping2 = {\n",
    "    0: 0,\n",
    "    91: 1,\n",
    "    132: 2,\n",
    "    211: 3\n",
    "}\n",
    "\n",
    "# Convert original segmap to 2d with classes\n",
    "def create_anno(anno):\n",
    "    anno_reshaped = rgb2gray(anno).astype(int)\n",
    "    for k in mapping:\n",
    "        anno_reshaped[anno_reshaped==k] = mapping[k]\n",
    "    return anno_reshaped\n",
    "\n",
    "# Convert imgaug segmap to 2d with classes\n",
    "def seg_to_anno(seg):\n",
    "    anno = rgb2gray(seg).astype(int)\n",
    "    for k in mapping2:\n",
    "        anno[anno==k] = mapping2[k]\n",
    "    return anno\n",
    "\n",
    "# ============================================================================\n",
    "# Image Augmentors\n",
    "seq = iaa.Sequential([\n",
    "    iaa.HorizontalFlip(0.5),\n",
    "    iaa.Affine(rotate=(-180, 180)),\n",
    "    # iaa.Dropout(p=(0, 0.1)),\n",
    "    # iaa.Sharpen((0.0, 1.0)),\n",
    "    # iaa.ElasticTransformation(alpha=50, sigma=5),\n",
    "    iaa.CropToFixedSize(width=crop_size, height=crop_size)\n",
    "], random_order=False)\n",
    "\n",
    "# Class to load + process data\n",
    "class Custom_Data(data.Dataset):\n",
    "    def __init__(self, path_train, path_anno):\n",
    "\n",
    "        # Get all raw + annotated images\n",
    "        raw_img = os.listdir(path_train)\n",
    "        anno_img = os.listdir(path_anno)\n",
    "        raw_img.sort()\n",
    "        anno_img.sort()\n",
    "        raw_imgs = [os.path.join(path_train, img) for img in raw_img]\n",
    "        anno_imgs = [os.path.join(path_anno, img) for img in anno_img]\n",
    "\n",
    "        # Select only images with at least 3 classes represented\n",
    "        raw_new, anno_new = [], []\n",
    "        thresh = 512 * 512 / 2\n",
    "        for i in range(len(anno_imgs)):\n",
    "            segmap = create_anno(np.array(Image.open(anno_imgs[i])))\n",
    "            if (len(np.unique(segmap))>=3 and len(segmap[segmap == 0])<thresh):\n",
    "                raw_new = np.append(np.append(raw_new, raw_imgs[i]), raw_imgs[i])\n",
    "                anno_new = np.append(np.append(anno_new, anno_imgs[i]), anno_imgs[i])\n",
    "\n",
    "        # print(len(raw_imgs), len(raw_new))\n",
    "        self.raw_img = raw_new\n",
    "        self.anno_img = anno_new\n",
    "\n",
    "    def __getitem__(self, index, plots=False):\n",
    "\n",
    "        # Get raw img + segmap at index\n",
    "        raw_img_path = self.raw_img[index]\n",
    "        raw_img = np.array(Image.open(raw_img_path))\n",
    "        anno_img_path = self.anno_img[index]\n",
    "        anno_img = np.array(Image.open(anno_img_path))\n",
    "\n",
    "        # Format segmap\n",
    "        anno_img = create_anno(anno_img).astype('int32')\n",
    "        seg_map = SegmentationMapsOnImage(anno_img, shape=anno_img.shape)\n",
    "\n",
    "        # print(raw_img_path, anno_img_path)\n",
    "\n",
    "        # Perform data augmentations to generate 2 sets of augmented data\n",
    "        raw_aug, seg_aug = seq(image=raw_img, segmentation_maps=seg_map)\n",
    "        anno_aug = seg_aug.draw()[0]\n",
    "        anno_aug = seg_to_anno(anno_aug)\n",
    "\n",
    "        # Plot images to compare\n",
    "        if plots:\n",
    "            plt.figure()\n",
    "            plt.subplot(2,2,1)\n",
    "            plt.imshow(raw_img)\n",
    "            plt.subplot(2,2,2)\n",
    "            plt.imshow(anno_img)\n",
    "            plt.subplot(2,2,3)\n",
    "            plt.imshow(raw_aug)\n",
    "            plt.subplot(2,2,4)\n",
    "            plt.imshow(anno_aug)\n",
    "            plt.show()\n",
    "\n",
    "        return (raw_aug, anno_aug)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_img)\n",
    "\n",
    "\n",
    "\n",
    "train_data = Custom_Data(path_train, path_anno)\n",
    "train_loader = DataLoader(train_data, batch_size=batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training dataloder shape check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:10:57.919578Z",
     "start_time": "2019-12-18T21:10:57.625670Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "train_input, train_target = train_iter.next()\n",
    "print(\"train_input size = {}.\".format(train_input.size()))\n",
    "print(\"train_target size = {}.\".format(train_target.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generator for Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter in test batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:10:57.922547Z",
     "start_time": "2019-12-18T21:10:57.920646Z"
    }
   },
   "outputs": [],
   "source": [
    "path_test_input = path_test_raw\n",
    "path_test_target = path_test_anno\n",
    "\n",
    "num_batch = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:10:57.930214Z",
     "start_time": "2019-12-18T21:10:57.923554Z"
    }
   },
   "outputs": [],
   "source": [
    "class Custom_Data(data.Dataset):\n",
    "    def __init__(self, path_test_input, path_test_target):\n",
    "        input = os.listdir(path_test_input)\n",
    "        self.input = sorted([os.path.join(path_test_input, a) for a in input])\n",
    "\n",
    "        target = os.listdir(path_test_target)\n",
    "        self.target = sorted([os.path.join(path_test_target, a) for a in target])\n",
    "\n",
    "        self.mapping = {\n",
    "            0:0,\n",
    "            76:1,\n",
    "            149:2,\n",
    "            225:3\n",
    "        }\n",
    "\n",
    "    def mapping_to_class(self, target):\n",
    "        for k in self.mapping:\n",
    "            target[target==k] = self.mapping[k]\n",
    "        return target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # test input data\n",
    "        test_input_path = self.input[index]\n",
    "        test_input = Image.open(test_input_path)\n",
    "        # test_input = T.RandomCrop(256)(test_input)\n",
    "        test_input = T.ToTensor()(test_input)\n",
    "\n",
    "        # test target data\n",
    "        test_target_path = self.target[index]\n",
    "        test_target = Image.open(test_target_path)\n",
    "        # test_target = T.RandomCrop(256)(test_target)\n",
    "        test_target = T.ToTensor()(test_target)\n",
    "        test_target_RGB = test_target\n",
    "\n",
    "        # mapping target to class index\n",
    "        test_target = T.ToPILImage()(test_target).convert(\"L\")\n",
    "        test_target_grey = torch.from_numpy(np.array(test_target))\n",
    "        test_target = self.mapping_to_class(test_target_grey)\n",
    "    \n",
    "        return test_input, test_target, test_target_RGB, test_target_grey, test_input_path, test_target_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "test_data = Custom_Data(path_test_input, path_test_target)\n",
    "test_loader = DataLoader(test_data, batch_size=num_batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test dataloader shape check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:10:58.086178Z",
     "start_time": "2019-12-18T21:10:57.931594Z"
    }
   },
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)\n",
    "test_input, test_target, test_target_RGB, test_target_grey, test_input_path, test_target_path = test_iter.next()\n",
    "print(\"test_input size = {}.\".format(test_input.size()))\n",
    "print(\"test_target size = {}.\".format(test_target.size()))\n",
    "print(\"test_target_grey size = {}.\".format(test_target_grey.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:10:58.298152Z",
     "start_time": "2019-12-18T21:10:58.088099Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encode_conv_bn_x2(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super(Encode_conv_bn_x2, self).__init__()\n",
    "        batchNorm_momentum = 0.1\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_, out, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out, momentum= batchNorm_momentum)\n",
    "        self.conv2 = nn.Conv2d(out, out, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out, momentum= batchNorm_momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        return x    \n",
    "    \n",
    "class Encode_conv_bn_x3(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super(Encode_conv_bn_x3, self).__init__()\n",
    "        batchNorm_momentum = 0.1\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_, out, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out, momentum= batchNorm_momentum)\n",
    "        self.conv2 = nn.Conv2d(out, out, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out, momentum= batchNorm_momentum)\n",
    "        self.conv3 = nn.Conv2d(out, out, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(out, momentum= batchNorm_momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Dencode_conv_bn_x1(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super(Dencode_conv_bn_x1, self).__init__()\n",
    "        batchNorm_momentum = 0.1\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_, in_, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_, momentum= batchNorm_momentum)   \n",
    "        self.conv2= nn.Conv2d(in_, out, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "    \n",
    "class Dencode_conv_bn_x2(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super(Dencode_conv_bn_x2, self).__init__()\n",
    "        batchNorm_momentum = 0.1\n",
    "        \n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_, in_, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_, momentum= batchNorm_momentum)\n",
    "        \n",
    "        self.conv2= nn.Conv2d(in_, out, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out, momentum= batchNorm_momentum)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Dencode_conv_bn_x3(nn.Module):\n",
    "    def __init__(self, in_, out):\n",
    "        super(Dencode_conv_bn_x3, self).__init__()\n",
    "        batchNorm_momentum = 0.1\n",
    "        \n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_, in_, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_, momentum= batchNorm_momentum)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_, in_, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(in_, momentum= batchNorm_momentum)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_, out, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(out, momentum= batchNorm_momentum)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self,input_nbr = 3,label_nbr = 4):\n",
    "        '''\n",
    "        input_nbr: the number of channels of input image;\n",
    "        label_nbr: the number of classes need to be segmented\n",
    "        '''\n",
    "        super(SegNet, self).__init__()\n",
    "        batchNorm_momentum = 0.1\n",
    "        \n",
    "        self.encode1=Encode_conv_bn_x2(input_nbr,64)\n",
    "        self.encode2=Encode_conv_bn_x2(64,128)\n",
    "        self.encode3=Encode_conv_bn_x3(128,256)\n",
    "        self.encode4=Encode_conv_bn_x3(256,512)\n",
    "        self.encode5=Encode_conv_bn_x3(512,512)\n",
    "        \n",
    "        self.dencode5=Dencode_conv_bn_x3(512,512)\n",
    "        self.dencode4=Dencode_conv_bn_x3(512,256)\n",
    "        self.dencode3=Dencode_conv_bn_x2(256,128)\n",
    "        self.dencode2=Dencode_conv_bn_x2(128,64)\n",
    "        self.dencode1=Dencode_conv_bn_x1(64,label_nbr)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Stage 1\n",
    "        x1=F.relu(self.encode1(x))\n",
    "        self.x1p, self.id1 = F.max_pool2d(x1,kernel_size=2, stride=2,return_indices=True)\n",
    "\n",
    "        # Stage 2\n",
    "        x2=F.relu(self.encode2(self.x1p))\n",
    "        self.x2p, self.id2 = F.max_pool2d(x2,kernel_size=2, stride=2,return_indices=True)\n",
    "\n",
    "        # Stage 3\n",
    "        x3=F.relu(self.encode3(self.x2p))\n",
    "        self.x3p, self.id3 = F.max_pool2d(x3,kernel_size=2, stride=2,return_indices=True)\n",
    "\n",
    "        # Stage 4\n",
    "        x4=F.relu(self.encode4(self.x3p))\n",
    "        self.x4p, self.id4 = F.max_pool2d(x4,kernel_size=2, stride=2,return_indices=True)\n",
    "\n",
    "        # Stage 5\n",
    "        x5=F.relu(self.encode5(self.x4p))\n",
    "        self.x5p, self.id5 = F.max_pool2d(x5,kernel_size=2, stride=2,return_indices=True)\n",
    "        \n",
    "        # Stage 5d\n",
    "        x5 = F.max_unpool2d(self.x5p, self.id5, kernel_size=2, stride=2)\n",
    "        x5=F.relu(self.dencode5(x5))\n",
    "\n",
    "        # Stage 4d\n",
    "        x4= F.max_unpool2d(x5, self.id4, kernel_size=2, stride=2)\n",
    "        x4=F.relu(self.dencode4(x4))\n",
    "        \n",
    "        \n",
    "        # Stage 3d\n",
    "        x3= F.max_unpool2d(x4, self.id3, kernel_size=2, stride=2)\n",
    "        x3=F.relu(self.dencode3(x3))\n",
    "\n",
    "        # Stage 2d\n",
    "        x2= F.max_unpool2d(x3, self.id2, kernel_size=2, stride=2)\n",
    "        x2=F.relu(self.dencode2(x2))\n",
    "\n",
    "        # Stage 1d\n",
    "        x1 = F.max_unpool2d(x2, self.id1, kernel_size=2, stride=2)\n",
    "        x1=self.dencode1(x1)\n",
    "        return x1\n",
    "\n",
    "net = SegNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:11:01.320173Z",
     "start_time": "2019-12-18T21:10:58.299114Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "net = net.cuda()\n",
    "summary(net,(3, 256, 256), batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter in train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:11:01.323342Z",
     "start_time": "2019-12-18T21:11:01.321205Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "learning_rate=0.0001\n",
    "model_path = '/home/renping/02456 DeepLearning Project/net_trained/net_trained.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:12:42.375341Z",
     "start_time": "2019-12-18T21:11:01.324439Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# mapping = {\n",
    "#     0: 0, # no data\n",
    "#     76: 1, # soil\n",
    "#     149: 2, # crops\n",
    "#     225: 3 # weeds\n",
    "# }\n",
    "\n",
    "\n",
    "# initialize the net, loss, optimizer\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "if use_cuda:\n",
    "    print(\"Running on GPU!\")\n",
    "    net = net.cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "else:\n",
    "    print(\"Running on CPU!\")\n",
    "    net = net\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "print(\"Start training!\")\n",
    "print(\"Total training epoch: {}.\".format(num_epoch))\n",
    "\n",
    "total_loss = []\n",
    "total_accuracy = []\n",
    "\n",
    "total_loss_test = []\n",
    "total_accuracy_test = []\n",
    "\n",
    "for epoch in tqdm(range(0, num_epoch)):\n",
    "\n",
    "    train_epoch_loss = 0.0\n",
    "    net.train()\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        inputs, targets = train_data\n",
    "        inputs = inputs.permute(0,3,1,2)\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        targets = targets.type(torch.LongTensor)\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        # print(\"inpusts size = {}\".format(inputs.size()))\n",
    "        # print(\"targets size = {}\".format(targets.size()))\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        outputs = net.forward(inputs)\n",
    "        # print(\"outputs size = {}\".format(outputs.size()))\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss = train_epoch_loss + loss.item()\n",
    "        \n",
    "    total_loss.append(train_epoch_loss/88)\n",
    "\n",
    "    test_epoch_loss = 0.0\n",
    "    net.eval()\n",
    "    for j, test_data in enumerate(test_loader):\n",
    "        test_input, test_target, _, _, _, _ = test_data\n",
    "        test_input = test_input.type(torch.FloatTensor)\n",
    "        test_target = test_target.type(torch.LongTensor)\n",
    "        if use_cuda:\n",
    "            test_input = test_input.cuda()\n",
    "            test_target = test_target.cuda()\n",
    "        with torch.no_grad():\n",
    "            test_output = net.forward(test_input)\n",
    "            loss_test = criterion(test_output, test_target)\n",
    "\n",
    "        test_epoch_loss = test_epoch_loss + loss_test.item()\n",
    "\n",
    "    total_loss_test.append(test_epoch_loss/35)\n",
    "\n",
    "    # print train epoch loss every epoch\n",
    "    print(\"epoch {}/{}, train loss {}\".format(epoch+1, num_epoch, train_epoch_loss/88))\n",
    "\n",
    "    # print test epoch loss every epoch\n",
    "    print(\"epoch {}/{}, test loss {}\".format(epoch+1, num_epoch, test_epoch_loss/35))\n",
    "\n",
    "\n",
    "torch.save(net.state_dict(), model_path)\n",
    "\n",
    "print(\"Trained Model Saved!\")\n",
    "print(\"Training Finished!\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"loss\")\n",
    "plt.plot(total_loss, label=\"train loss\")\n",
    "plt.plot(total_loss_test, label= \"test loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc=1)\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.savefig(\"loss\")\n",
    "plt.show()\n",
    "print(\"loss figure saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T21:13:17.335316Z",
     "start_time": "2019-12-18T21:12:42.376926Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import seaborn as sbn\n",
    "\n",
    "\n",
    "# mapping = {\n",
    "#     0: 0, # no data\n",
    "#     76: 1, # soil\n",
    "#     149: 2, # crops\n",
    "#     225: 3 # weeds\n",
    "# }\n",
    "\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "net.eval()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print(\"Running on GPU!\")\n",
    "    net = net.cuda()\n",
    "\n",
    "path_to_images = path_test_raw\n",
    "path_to_annotations = path_test_anno\n",
    "\n",
    "img_list = glob.glob(path_to_images+os.sep+\"*.png\")\n",
    "img_list = sorted(img_list)\n",
    "anno_list = glob.glob(path_to_annotations+os.sep+\"*.png\")\n",
    "anno_list = sorted(anno_list)\n",
    "\n",
    "\n",
    "preds = []\n",
    "for rand_int in range(len(img_list)):\n",
    "    # rand_int = random.randint(0, len(img_list)-1)\n",
    "    # rand_int = random.randint(0, len(img_list)-1)\n",
    "\n",
    "    raw_img = np.array(Image.open(img_list[rand_int]))\n",
    "    show_anno = np.array(Image.open(anno_list[rand_int]).convert(\"L\"))\n",
    "\n",
    "\n",
    "    show_raw = raw_img\n",
    "\n",
    "    img = torch.from_numpy(raw_img).type(torch.FloatTensor).cuda()\n",
    "    img = img.permute(2,0,1)\n",
    "    # print(img.shape)\n",
    "\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    # print(img.shape)\n",
    "\n",
    "    pred = net(img)\n",
    "\n",
    "    # print(pred.shape)\n",
    "\n",
    "    pred = pred.squeeze()\n",
    "    # print(pred.shape)\n",
    "\n",
    "    pred_img = torch.argmax(pred, dim=0).cpu().numpy()\n",
    "    # print(\"{}th image:{} \".format(rand_int+1, np.unique(pred_img)))\n",
    "    preds.append(pred_img)\n",
    "\n",
    "# Utilities\n",
    "def color_mapping(img):\n",
    "    mapping_rev = {\n",
    "    0:0, # no data\n",
    "    76:1, # soil\n",
    "    149:2, # crops\n",
    "    225:3 # weeds\n",
    "    }\n",
    "    for item in mapping_rev:\n",
    "        img[img==item] = mapping_rev[item]\n",
    "    return img\n",
    "\n",
    "annotations_path = path_test_anno\n",
    "annotations_list = sorted(glob.glob(annotations_path+os.sep+'*.png'))\n",
    "\n",
    "annos = []\n",
    "for file in annotations_list:\n",
    "    anno = np.array(Image.open(file).convert('L'))\n",
    "    anno = color_mapping(anno)\n",
    "    annos.append(anno)\n",
    "annos = np.array(annos)\n",
    "print('Annotations shape: {}'.format(annos.shape))\n",
    "\n",
    "\n",
    "classes = ['No data', 'Soil', 'Crops', 'Weeds']\n",
    "colors = [(1.0, 1.0, 0.8980392156862745, 1.0), # no data\n",
    "         (0.7359477124183007, 0.8915032679738563, 0.5843137254901961, 1.0), # soil\n",
    "         (0.21568627450980393, 0.6196078431372549, 0.330718954248366, 1.0), # crops\n",
    "         (0.0, 0.27058823529411763, 0.1607843137254902, 1.0) # weeds\n",
    "         ]\n",
    "patches = [mpatches.Patch(color=colors[i], label=\"{l}\".format(l=classes[i])) for i in range(len(classes))]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "ex1 = 16\n",
    "ex2 = 10\n",
    "\n",
    "# Anno ex 1\n",
    "ax[0][0].imshow(annos[ex1], cmap=plt.cm.YlGn, vmin = 0, vmax = 3)\n",
    "ax[0][0].set_title('Annotation example 1')\n",
    "\n",
    "# Anno ex 2\n",
    "ax[1][0].imshow(annos[ex2], cmap=plt.cm.YlGn, vmin = 0, vmax = 3)\n",
    "ax[1][0].set_title('Annotation example 2')\n",
    "\n",
    "# Pred ex 1\n",
    "ax[0][1].imshow(preds[ex1], cmap=plt.cm.YlGn, vmin = 0, vmax = 3)\n",
    "ax[0][1].set_title('Prediction example 1')\n",
    "\n",
    "# Pred ex 2\n",
    "ax[1][1].imshow(preds[ex2], cmap=plt.cm.YlGn, vmin = 0, vmax = 3)\n",
    "ax[1][1].set_title('Prediction example 2')\n",
    "\n",
    "fig.legend(handles=patches, loc='right')\n",
    "# plt.show()\n",
    "\n",
    "preds = np.array(preds)\n",
    "\n",
    "cm_preds = np.reshape(preds, preds.shape[0]*preds.shape[1]*preds.shape[2])\n",
    "cm_annos = np.reshape(annos, annos.shape[0]*annos.shape[1]*annos.shape[2])\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "weights = compute_sample_weight(class_weight='balanced', y=cm_preds)\n",
    "cm = confusion_matrix(cm_annos, cm_preds, sample_weight=weights)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "sbn.heatmap(cm, xticklabels=classes, yticklabels=classes) # annot=True prints the actual numbers in the heatmap matrix\n",
    "plt.xlabel('Annotation')\n",
    "plt.ylabel('Prediction')\n",
    "\n",
    "plt.savefig(\"confusion matrix\")\n",
    "plt.show()\n",
    "print(\"confusion matrix figure saved!!\")\n",
    "\n",
    "f1 = 0\n",
    "for idx in range(len(annos)):\n",
    "     for classes in np.unique(annos[idx]):\n",
    "         if classes == 0:\n",
    "             continue\n",
    "     y_pred = (preds[idx]==classes)*1\n",
    "     y_true = (annos[idx]==classes)*1\n",
    "     f1 +=f1_score(y_true.reshape(-1), y_pred.reshape(-1), average='macro')\n",
    "\n",
    "f1 /= len(annos)\n",
    "print(\"F1 score: {}\".format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
